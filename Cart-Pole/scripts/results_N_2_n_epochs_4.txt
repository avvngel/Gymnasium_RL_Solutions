Discretizing environment...0.000s
Initializing EnvModel...0.004s
Initializing policy...0.001s
Beginning training loop...
#################### EPOCH 1 #########################
Exploring environment...
Exploration time: 10.536s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.025s
Policy Improvement: 8.148s
k = 2
Policy Evaluation: 0.023s
Policy Improvement: 8.133s
k = 3
Policy Evaluation: 0.023s
Policy Improvement: 8.152s
Policy iteration terminated in 3 iters and 24.505s.
Epoch 0 time: 35.041s
#################### EPOCH 2 #########################
Exploring environment...
Exploration time: 54.631s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.022s
Policy Improvement: 8.137s
k = 2
Policy Evaluation: 0.023s
Policy Improvement: 8.151s
k = 3
Policy Evaluation: 0.023s
Policy Improvement: 8.144s
Policy iteration terminated in 3 iters and 24.501s.
Epoch 1 time: 79.132s
#################### EPOCH 3 #########################
Exploring environment...
Exploration time: 51.071s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.024s
Policy Improvement: 8.142s
k = 2
Policy Evaluation: 0.023s
Policy Improvement: 8.143s
k = 3
Policy Evaluation: 0.023s
Policy Improvement: 8.146s
Policy iteration terminated in 3 iters and 24.500s.
Epoch 2 time: 75.572s
#################### EPOCH 4 #########################
Exploring environment...
Exploration time: 81.908s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.023s
Policy Improvement: 8.143s
Policy iteration terminated in 1 iters and 8.166s.
Epoch 3 time: 90.075s
Training finished in 279.819s
