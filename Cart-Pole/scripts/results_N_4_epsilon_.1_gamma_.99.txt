Discretizing environment...0.000s
Initializing EnvModel...0.024s
Initializing policy...0.006s
Beginning training loop...
#################### EPOCH 1 #########################
Exploring environment...
Exploration time: 33.823s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.168s
Policy Improvement: 15.405s
k = 2
Policy Evaluation: 0.174s
Policy Improvement: 15.407s
k = 3
Policy Evaluation: 0.179s
Policy Improvement: 15.394s
Policy iteration terminated in 3 iters and 46.728s.
Epoch 1 time: 80.551s
#################### EPOCH 2 #########################
Exploring environment...
Exploration time: 153.902s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.206s
Policy Improvement: 19.980s
k = 2
Policy Evaluation: 0.201s
Policy Improvement: 20.033s
k = 3
Policy Evaluation: 0.249s
Policy Improvement: 20.190s
Policy iteration terminated in 3 iters and 60.858s.
Epoch 2 time: 214.760s
#################### EPOCH 3 #########################
Exploring environment...
Exploration time: 298.926s
Average reward: 103.192
Beginning policy iteration...
k = 1
Policy Evaluation: 0.467s
Policy Improvement: 27.379s
k = 2
Policy Evaluation: 0.226s
Policy Improvement: 25.877s
Policy iteration terminated in 2 iters and 53.951s.
Epoch 3 time: 352.877s
#################### EPOCH 4 #########################
Exploring environment...
Exploration time: 299.741s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.234s
Policy Improvement: 27.698s
k = 2
Policy Evaluation: 0.341s
Policy Improvement: 27.827s
k = 3
Policy Evaluation: 0.529s
Policy Improvement: 27.860s
k = 4
Policy Evaluation: 0.337s
Policy Improvement: 27.749s
Policy iteration terminated in 4 iters and 112.576s.
Epoch 4 time: 412.318s
#################### EPOCH 5 #########################
Exploring environment...
Exploration time: 395.354s
Average reward: 138.535
Beginning policy iteration...
k = 1
Policy Evaluation: 0.292s
Policy Improvement: 28.720s
k = 2
Policy Evaluation: 0.404s
Policy Improvement: 28.741s
k = 3
Policy Evaluation: 0.300s
Policy Improvement: 28.717s
Policy iteration terminated in 3 iters and 87.176s.
Epoch 5 time: 482.530s
#################### EPOCH 6 #########################
Exploring environment...
Exploration time: 321.084s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.236s
Policy Improvement: 31.221s
k = 2
Policy Evaluation: 0.313s
Policy Improvement: 31.208s
Policy iteration terminated in 2 iters and 62.980s.
Epoch 6 time: 384.064s
#################### EPOCH 7 #########################
Exploring environment...
Exploration time: 404.303s
Average reward: 158.02
Beginning policy iteration...
k = 1
Policy Evaluation: 0.300s
Policy Improvement: 31.591s
k = 2
Policy Evaluation: 0.165s
Policy Improvement: 31.485s
Policy iteration terminated in 2 iters and 63.542s.
Epoch 7 time: 467.844s
#################### EPOCH 8 #########################
Exploring environment...
Exploration time: 292.592s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.275s
Policy Improvement: 31.606s
k = 2
Policy Evaluation: 0.210s
Policy Improvement: 31.660s
k = 3
Policy Evaluation: 0.249s
Policy Improvement: 31.719s
Policy iteration terminated in 3 iters and 95.719s.
Epoch 8 time: 388.311s
#################### EPOCH 9 #########################
Exploring environment...
Exploration time: 316.644s
Average reward: 165.097
Beginning policy iteration...
k = 1
Policy Evaluation: 0.429s
Policy Improvement: 32.695s
k = 2
Policy Evaluation: 0.167s
Policy Improvement: 33.302s
Policy iteration terminated in 2 iters and 66.592s.
Epoch 9 time: 383.236s
#################### EPOCH 10 #########################
Exploring environment...
Exploration time: 224.242s
Beginning policy iteration...
k = 1
Policy Evaluation: 0.174s
Policy Improvement: 34.021s
k = 2
Policy Evaluation: 0.164s
Policy Improvement: 32.471s
Policy iteration terminated in 2 iters and 66.830s.
Epoch 10 time: 291.073s
Training finished in 3457.564s
Average reward: 193.81
